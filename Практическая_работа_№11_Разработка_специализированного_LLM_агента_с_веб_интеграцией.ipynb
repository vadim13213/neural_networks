{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rpzUalTi5pEH"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vadim13213/neural_networks/blob/main/%D0%9F%D1%80%D0%B0%D0%BA%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%B0_%E2%84%9611_%D0%A0%D0%B0%D0%B7%D1%80%D0%B0%D0%B1%D0%BE%D1%82%D0%BA%D0%B0_%D1%81%D0%BF%D0%B5%D1%86%D0%B8%D0%B0%D0%BB%D0%B8%D0%B7%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%BD%D0%BE%D0%B3%D0%BE_LLM_%D0%B0%D0%B3%D0%B5%D0%BD%D1%82%D0%B0_%D1%81_%D0%B2%D0%B5%D0%B1_%D0%B8%D0%BD%D1%82%D0%B5%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D0%B5%D0%B9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Практическая работа №11. Разработка специализированного LLM-агента с веб-интеграцией**\n",
        "\n"
      ],
      "metadata": {
        "id": "rpzUalTi5pEH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Цель задания**\n"
      ],
      "metadata": {
        "id": "RWoMHWsn5qpn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Разработать узкоспециализированного интеллектуального агента на основе большой языковой модели (LLM) с возможностью получения данных из интернета и сохранения результатов работы в текстовом формате."
      ],
      "metadata": {
        "id": "0mNph7xz5rff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Описание задания**\n"
      ],
      "metadata": {
        "id": "0x4lVuHC5t6P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В рамках данной практической работы вам предстоит создать агента на базе LLM, который будет специализироваться на определенной предметной области (по вашему выбору). Агент должен уметь:\n",
        "1. Взаимодействовать с пользователем через чат-интерфейс\n",
        "2. Выполнять поиск актуальной информации в интернете посредством API TavilySearchResults\n",
        "3. Анализировать и обрабатывать полученные данные\n",
        "4. Формировать структурированные ответы на запросы пользователей\n",
        "5. Сохранять результаты взаимодействия в текстовый файл в удобочитаемом формате"
      ],
      "metadata": {
        "id": "mMmveaTh5vrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Требования к реализации**\n",
        "\n"
      ],
      "metadata": {
        "id": "wBZ6W1Fd50QH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Архитектура агента\n"
      ],
      "metadata": {
        "id": "Zi0WrWs751EE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Определите узкую специализацию вашего агента (например, медицинский консультант, финансовый аналитик, юридический помощник, технический эксперт и т.д.)\n",
        "- Продумайте структуру промптов, обеспечивающую удержание агентом своей роли и выполнение целевых функций\n",
        "- Реализуйте механизм обработки запросов, учитывающий специфику выбранной предметной области"
      ],
      "metadata": {
        "id": "6O0gyVTW519G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Интеграция с внешними источниками данных\n"
      ],
      "metadata": {
        "id": "d1Iw-u4Q54SX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Подключите инструмент TavilySearchResults для получения актуальной информации из сети\n",
        "- Реализуйте логику формирования поисковых запросов на основе пользовательских обращений\n",
        "- Обеспечьте корректную обработку и интеграцию результатов поиска в контекст беседы с пользователем\n",
        "- Документация по TavilySearchResults: [https://python.langchain.com/docs/integrations/tools/tavily_search](https://python.langchain.com/docs/integrations/tools/tavily_search)"
      ],
      "metadata": {
        "id": "4stauTN855XF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Пользовательский интерфейс\n"
      ],
      "metadata": {
        "id": "ycuYbXKo57K6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Используйте компонент gr.Chatbot из библиотеки Gradio в качестве основы для интерфейса\n",
        "- Добавьте необходимые элементы управления (поле ввода, кнопки и т.д.)\n",
        "- Обеспечьте корректное отображение результатов поиска и ответов агента\n",
        "- Документация по Gradio: [https://www.gradio.app/docs/chatbot](https://www.gradio.app/docs/chatbot)"
      ],
      "metadata": {
        "id": "ZNPS6vYS574B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Сохранение результатов\n"
      ],
      "metadata": {
        "id": "wzpZPU0U59sI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Реализуйте функционал для сохранения истории взаимодействия в текстовый файл\n",
        "- Обеспечьте форматирование выходного файла (структурирование диалога, выделение запросов и ответов)\n",
        "- Предусмотрите возможность выбора пользователем имени и расположения файла"
      ],
      "metadata": {
        "id": "VjjlJb9h5-r4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## **Ход выполнения работы**"
      ],
      "metadata": {
        "id": "p5JPGkl87NSZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Подготовительный этап**\n",
        "   - Установите необходимые библиотеки (LangChain, Gradio и др.)\n",
        "   - Получите API-ключи для доступа к языковой модели и TavilySearchResults\n",
        "   - Определите специализацию вашего агента и основные сценарии использования\n",
        "\n",
        "2. **Разработка ядра агента**\n",
        "   - Настройте базовую цепочку обработки запросов (можно реализовать с использованием [LangChain](https://python.langchain.com/docs/tutorials/rag/)*,  а можно просто прописать новое обращение к llm, включающее в себя ее прошлый ответ + дополнительный промт)\n",
        "   - Интегрируйте инструмент TavilySearchResults\n",
        "   - Разработайте систему промптов для специализации агента\n",
        "\n",
        "3. **Создание пользовательского интерфейса**\n",
        "   - Реализуйте чат-интерфейс на базе gr.Chatbot\n",
        "   - Добавьте элементы управления и настройте обработчики событий\n",
        "   - Обеспечьте отображение промежуточных результатов работы агента\n",
        "\n",
        "4. **Функционал сохранения**\n",
        "   - Разработайте механизм форматирования истории беседы\n",
        "   - Реализуйте функции для сохранения данных в текстовый файл\n",
        "   - Добавьте кнопку или другой элемент управления для активации сохранения\n",
        "\n",
        "5. **Тестирование и отладка**\n",
        "   - Проверьте работу агента на различных сценариях использования\n",
        "   - Убедитесь в корректности обработки запросов и формирования ответов\n",
        "   - Протестируйте сохранение результатов в файл\n",
        "\n",
        "\n",
        "   *[LangChain](https://python.langchain.com/docs/tutorials/rag/) - Фреймворк для разработки приложений на основе LLM, упрощающий создание цепочек обработки, управление памятью и интеграцию с различными компонентами.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8F8IsND95lIG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Примечания**\n"
      ],
      "metadata": {
        "id": "EA148tES7TuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "- При разработке промптов для специализации агента учитывайте особенности выбранной предметной области\n",
        "- Для повышения качества работы агента можно использовать техники \"chain-of-thought\" и \"retrieval-augmented generation\"\n",
        "- Обратите внимание на обработку ситуаций, когда поиск в интернете не дает релевантных результатов"
      ],
      "metadata": {
        "id": "g7JrYKG57S8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM-агент психолог"
      ],
      "metadata": {
        "id": "KljtfB3SRr-d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Подготовка (библиотеки + ключи)"
      ],
      "metadata": {
        "id": "arixkJSaR02C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers accelerate gradio langchain tavily-python bitsandbytes"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WRuXVGTbTNKe"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
        "import bitsandbytes\n",
        "import torch\n",
        "import datetime\n",
        "from tavily import TavilyClient\n",
        "import os"
      ],
      "metadata": {
        "id": "CLw4MSHiRzjz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "os.environ[\"HUGGINGFACE_API_KEY\"] = userdata.get(\"HUGGINGFACE_API_KEY\")"
      ],
      "metadata": {
        "id": "Nbiowkq-TO93"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=os.environ[\"HUGGINGFACE_API_KEY\"])"
      ],
      "metadata": {
        "id": "Ms1L5r0BxTHp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Промпт с chain-of-thought"
      ],
      "metadata": {
        "id": "Tv56_7_USOaj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(history, user_input, search_info=None):\n",
        "    intro = (\n",
        "        \"Ты — бывалый старослужащий, который прошёл не одну учебку и знаешь армейскую службу как свои пять пальцев.\"\n",
        "\"Твоя цель — объяснять новобранцам армейские премудрости так, чтобы даже салага с первого раза всё понял.\"\n",
        "\"Разжёвывай информацию пошагово, как устав, но с фирменными шутками в стиле Шматко.\"\n",
        "\"Избегай заумных терминов — если без них никак, переводи на солдатский язык.\"\n",
        "\"Держи армейский позитив: даже за промахи не ругай, а учи, как настоящий дед.\"\n",
        "\"Не выдавай себя за программу или бота — ты ветеран, который хочет, чтобы у новобранца всё получилось.\"\n",
        "\"Если попросят — предлагай альтернативные решения, как бывалый служака.\"\n",
        "\"При сложных вопросах разбирай ситуацию постепенно, как разбор полётов.\"\n",
        "\"Если спросят кто ты — отвечай, что учишь людей армейской смекалке.\"\n",
        "\"Никогда не упоминай, что ты бот, ИИ или компьютерная программа — ты живой старослужащий.\"\n",
        "\n",
        "\"Пример работы:\"\n",
        "\"— Как правильно чистить картошку на кухне?\"\n",
        "\"— Ты чё, десантник? Берёшь нож, снимаешь кожуру как старую нашивку, и чтоб глазков не осталось! Нет ножа? Используй ложку — в армии приспосабливаться надо!\"\\n\\n\"\n",
        "    )\n",
        "    if search_info:\n",
        "        intro += f\"(🔎 Использован внешний источник: {search_info})\\n\\n\"\n",
        "\n",
        "    dialog = \"\"\n",
        "    for turn in history:\n",
        "        dialog += f\"Пользователь: {turn['user']}\\nПсихолог: {turn['agent']}\\n\"\n",
        "    dialog += f\"Пользователь: {user_input}\\nПсихолог (размышляет шаг за шагом):\"\n",
        "    return intro + dialog"
      ],
      "metadata": {
        "id": "8UViZKJKSQdz",
        "outputId": "02211b74-3864-4caa-9dfb-a0e2e9fbd03a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "unexpected character after line continuation character (<ipython-input-5-459467ac1c39>, line 16)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-459467ac1c39>\"\u001b[0;36m, line \u001b[0;32m16\u001b[0m\n\u001b[0;31m    \"— Ты чё, десантник? Берёшь нож, снимаешь кожуру как старую нашивку, и чтоб глазков не осталось! Нет ножа? Используй ложку — в армии приспосабливаться надо!\"\\n\\n\"\u001b[0m\n\u001b[0m                                                                                                                                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected character after line continuation character\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Модель"
      ],
      "metadata": {
        "id": "VLCyeT7ZSQvp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    load_in_8bit=True\n",
        ")\n",
        "\n",
        "chat_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "IbIb838ISUjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Поиск"
      ],
      "metadata": {
        "id": "j3YIfBELSUs0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
        "\n",
        "def search_web(query):\n",
        "    try:\n",
        "        result = tavily_client.search(query=query, search_depth=\"advanced\", max_results=3)\n",
        "        if result and result.get(\"results\"):\n",
        "            first = result[\"results\"][0]\n",
        "            return f\"{first['title']} — {first['url']}\\n{first['content']}\"\n",
        "    except Exception as e:\n",
        "        print(f\"[!] Поиск не удался: {e}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "Pma9CS-sSXkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Основные функции (генерация ответа; сохранение истории в виде форматированного документа)"
      ],
      "metadata": {
        "id": "hWg8MGNnSYBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chat(user_input, chat_history):\n",
        "    if chat_history is None:\n",
        "        chat_history = []\n",
        "\n",
        "    search_result = search_web(user_input)\n",
        "    prompt = generate_prompt(chat_history, user_input, search_info=search_result)\n",
        "\n",
        "    output = chat_pipeline(prompt, max_new_tokens=700, do_sample=True, temperature=0.6)[0][\"generated_text\"]\n",
        "    response = output.split(\"Повар\")[-1].strip().lstrip(\":\").strip()\n",
        "\n",
        "    chat_history.append({\"user\": user_input, \"agent\": response})\n",
        "\n",
        "    gr_chat_history = [[turn[\"user\"], turn[\"agent\"]] for turn in chat_history]\n",
        "\n",
        "    return gr_chat_history, chat_history"
      ],
      "metadata": {
        "id": "uaqdUWJyh1kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_chat(chat_history):\n",
        "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
        "    filename = f\"История_чата_{timestamp}.txt\"\n",
        "\n",
        "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"🧠 История консультации с LLM-агентом поваром\\n\")\n",
        "        f.write(f\"Дата: {datetime.datetime.now().strftime('%d.%m.%Y %H:%M')}\\n\")\n",
        "        f.write(\"=\" * 40 + \"\\n\\n\")\n",
        "        for i, turn in enumerate(chat_history, 1):\n",
        "            f.write(f\"💬 Диалог {i}\\n\")\n",
        "            f.write(f\"👤 Пользователь:\\n{turn['user']}\\n\\n\")\n",
        "            f.write(f\"🧑‍⚕️ Повар:\\n{turn['agent']}\\n\")\n",
        "            f.write(\"-\" * 40 + \"\\n\\n\")\n",
        "    return f\"История сохранена: {filename}\""
      ],
      "metadata": {
        "id": "T_NvdY63ZtZg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Интерфейс (Gradio chat)"
      ],
      "metadata": {
        "id": "xX29TdAgTAdW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 🧠 Чат с LLM-агентом психологом\")\n",
        "    chatbot = gr.Chatbot(label=\"Чат\", height=400, render_markdown=True, type='messages')\n",
        "\n",
        "    user_input = gr.Textbox(placeholder=\"Напишите что вас интересует...\", show_label=False)\n",
        "    state = gr.State([])\n",
        "\n",
        "    with gr.Row():\n",
        "        send_button = gr.Button(\"Отправить\")\n",
        "        save_button = gr.Button(\"💾 Сохранить историю\")\n",
        "\n",
        "    output_message = gr.Markdown(\"\")\n",
        "\n",
        "    send_button.click(chat, inputs=[user_input, state], outputs=[chatbot, state])\n",
        "    save_button.click(save_chat, inputs=[state], outputs=[output_message])\n",
        "\n",
        "demo.launch(debug=True)"
      ],
      "metadata": {
        "id": "ddI9Y8eITKV8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}